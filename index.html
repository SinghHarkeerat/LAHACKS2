<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Lip Tracking with Speech Recognition</title>
    <style>
        :root {
            --primary: #4361ee;
            --secondary: #3f37c9;
            --accent: #4895ef;
            --light: #f8f9fa;
            --dark: #212529;
            --success: #4cc9f0;
            --warning: #f72585;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background-color: var(--light);
            color: var(--dark);
            min-height: 100vh;
            padding: 2rem;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        
        header {
            text-align: center;
            margin-bottom: 2rem;
        }
        
        h1 {
            color: var(--primary);
            margin-bottom: 0.5rem;
        }
        
        .subtitle {
            color: var(--secondary);
            opacity: 0.8;
        }
        
        .app-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
        }
        
        @media (max-width: 768px) {
            .app-grid {
                grid-template-columns: 1fr;
            }
        }
        
        .video-section, .output-section {
            background: white;
            border-radius: 10px;
            padding: 1.5rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        
        .section-title {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 1rem;
            color: var(--secondary);
        }
        
        .section-title svg {
            width: 24px;
            height: 24px;
        }
        
        .video-container {
            position: relative;
            width: 100%;
            margin-bottom: 1rem;
        }
        
        video, canvas {
            width: 100%;
            border-radius: 8px;
            display: block;
        }
        
        .lip-mask-container {
            position: relative;
            width: 100%;
            height: 150px;
            background: var(--dark);
            border-radius: 8px;
            overflow: hidden;
            margin-bottom: 1rem;
        }
        
        #lipMaskCanvas {
            width: 100%;
            height: 100%;
        }
        
        .controls {
            display: flex;
            gap: 1rem;
            margin-bottom: 1rem;
        }
        
        button {
            padding: 0.5rem 1rem;
            border: none;
            border-radius: 5px;
            background-color: var(--primary);
            color: white;
            cursor: pointer;
            font-weight: 500;
            transition: all 0.2s;
            flex: 1;
        }
        
        button:hover {
            background-color: var(--secondary);
            transform: translateY(-2px);
        }
        
        button:disabled {
            background-color: #ccc;
            cursor: not-allowed;
            transform: none;
        }
        
        .btn-danger {
            background-color: var(--warning);
        }
        
        .btn-success {
            background-color: var(--success);
        }
        
        .speech-output {
            height: 300px;
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 1rem;
            overflow-y: auto;
            background-color: #f8f9fa;
            margin-bottom: 1rem;
        }
        
        .speech-bubble {
            background-color: white;
            border-radius: 15px;
            padding: 0.75rem 1rem;
            margin-bottom: 0.5rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            position: relative;
            max-width: 80%;
            word-wrap: break-word;
        }
        
        .speech-bubble.user {
            background-color: var(--primary);
            color: white;
            margin-left: auto;
        }
        
        .speech-bubble.system {
            background-color: #e9ecef;
            margin-right: auto;
        }
        
        .status-indicator {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem;
            border-radius: 5px;
            margin-bottom: 1rem;
        }
        
        .status-dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background-color: #6c757d;
        }
        
        .status-dot.active {
            background-color: var(--success);
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.2); }
            100% { transform: scale(1); }
        }
        
        .threshold-control {
            margin-bottom: 1rem;
        }
        
        label {
            display: block;
            margin-bottom: 0.5rem;
            font-weight: 500;
        }
        
        input[type="range"] {
            width: 100%;
        }
        
        .threshold-value {
            text-align: center;
            font-weight: bold;
            color: var(--primary);
        }
        
        .lip-stats {
            display: flex;
            justify-content: space-between;
            margin-bottom: 1rem;
        }
        
        .stat-box {
            background: #f1f3f5;
            padding: 0.5rem;
            border-radius: 5px;
            text-align: center;
            flex: 1;
            margin: 0 0.25rem;
        }
        
        .stat-value {
            font-weight: bold;
            color: var(--primary);
        }
        
        .stat-label {
            font-size: 0.8rem;
            color: #6c757d;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Real-Time Lip Tracking</h1>
            <p class="subtitle">With speech recognition and visual feedback</p>
        </header>
        
        <div class="app-grid">
            <div class="video-section">
                <h2 class="section-title">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z" />
                    </svg>
                    Video Feed
                </h2>
                
                <div class="status-indicator">
                    <div class="status-dot" id="cameraStatus"></div>
                    <span id="cameraStatusText">Camera: Loading...</span>
                </div>
                
                <div class="video-container">
                    <video id="video" playsinline autoplay muted></video>
                    <canvas id="canvas"></canvas>
                </div>
                
                <div class="lip-mask-container">
                    <canvas id="lipMaskCanvas"></canvas>
                </div>
                
                <div class="lip-stats">
                    <div class="stat-box">
                        <div class="stat-value" id="opennessValue">0</div>
                        <div class="stat-label">Openness</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value" id="speedValue">0</div>
                        <div class="stat-label">Speed</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value" id="statusValue">Idle</div>
                        <div class="stat-label">Status</div>
                    </div>
                </div>
                
                <div class="threshold-control">
                    <label for="thresholdSlider">Lip Movement Sensitivity</label>
                    <input type="range" id="thresholdSlider" min="5" max="50" value="15">
                    <div class="threshold-value">Threshold: <span id="thresholdValue">15</span></div>
                </div>
                
                <div class="controls">
                    <button id="startBtn">Start</button>
                    <button id="stopBtn" disabled>Stop</button>
                </div>
            </div>
            
            <div class="output-section">
                <h2 class="section-title">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                    </svg>
                    Speech Output
                </h2>
                
                <div class="status-indicator">
                    <div class="status-dot" id="speechStatus"></div>
                    <span id="speechStatusText">Speech Recognition: Ready</span>
                </div>
                
                <div class="speech-output" id="speechOutput">
                    <div class="speech-bubble system">
                        <strong>System:</strong> Application loaded. Click "Start" to begin.
                    </div>
                </div>
                
                <div class="controls">
                    <button id="clearBtn" class="btn-danger">Clear Output</button>
                    <button id="rephraseBtn" class="btn-success">Rephrase Last</button>
                </div>
            </div>
        </div>
    </div>

    <!-- MediaPipe and Camera Utils -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>

    <script>
        // DOM Elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const lipMaskCanvas = document.getElementById('lipMaskCanvas');
        const ctx = canvas.getContext('2d');
        const lipCtx = lipMaskCanvas.getContext('2d');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const clearBtn = document.getElementById('clearBtn');
        const rephraseBtn = document.getElementById('rephraseBtn');
        const speechOutput = document.getElementById('speechOutput');
        const thresholdSlider = document.getElementById('thresholdSlider');
        const thresholdValue = document.getElementById('thresholdValue');
        const cameraStatus = document.getElementById('cameraStatus');
        const cameraStatusText = document.getElementById('cameraStatusText');
        const speechStatus = document.getElementById('speechStatus');
        const speechStatusText = document.getElementById('speechStatusText');
        const opennessValue = document.getElementById('opennessValue');
        const speedValue = document.getElementById('speedValue');
        const statusValue = document.getElementById('statusValue');

        // App State
        let stream = null;
        let isRunning = false;
        let isTalking = false;
        let lipDistanceThreshold = 15;
        let speechRecognition = null;
        let lastSpeech = '';
        let camera = null;
        let faceMesh = null;
        
        // Lip tracking variables
        let previousLipDistance = 0;
        let previousTime = 0;
        let lipMovementSpeed = 0;
        let lipOpennessHistory = [];
        const HISTORY_LENGTH = 5;
        
        // Initialize the app
        async function init() {
            // Set up event listeners
            startBtn.addEventListener('click', startApp);
            stopBtn.addEventListener('click', stopApp);
            clearBtn.addEventListener('click', clearOutput);
            rephraseBtn.addEventListener('click', rephraseLast);
            thresholdSlider.addEventListener('input', updateThreshold);
            
            // Initialize camera
            await initCamera();
            
            // Initialize Face Mesh
            initFaceMesh();
        }
        
        // Initialize camera
        async function initCamera() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        width: 1280, 
                        height: 720,
                        facingMode: 'user' 
                    },
                    audio: false
                });
                video.srcObject = stream;
                
                // Set canvas dimensions to match video
                video.addEventListener('loadedmetadata', () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    lipMaskCanvas.width = 120;
                    lipMaskCanvas.height = 80;
                    
                    updateCameraStatus(true);
                });
            } catch (error) {
                console.error("Error accessing camera:", error);
                updateCameraStatus(false, "Camera access denied");
                addSpeechBubble("System", "Error: Could not access camera", "system");
            }
        }
        
        // Initialize Face Mesh
        function initFaceMesh() {
            faceMesh = new FaceMesh({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
            });
            
            faceMesh.setOptions({
                maxNumFaces: 1,
                refineLandmarks: true,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });
            
            faceMesh.onResults(onFaceMeshResults);
        }
        
        // Process Face Mesh results
        function onFaceMeshResults(results) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            if (!isRunning) return;
            
            // Draw camera feed
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                const landmarks = results.multiFaceLandmarks[0];
                
                // Get lip landmarks (MediaPipe lip indices)
                const lipLandmarks = [
                    // Outer lips (clockwise)
                    61, 185, 40, 39, 37, 0, 267, 269, 270, 409,
                    // Inner lips (clockwise)
                    78, 191, 80, 81, 82, 13, 312, 311, 310, 415
                ];
                
                // Calculate mouth openness (using top and bottom inner lips)
                const upperLip = landmarks[13];  // Top inner lip
                const lowerLip = landmarks[14];   // Bottom inner lip
                const lipDistance = Math.abs(lowerLip.y - upperLip.y) * canvas.height;
                
                // Calculate lip movement speed
                const now = performance.now();
                if (previousTime > 0) {
                    const timeDelta = (now - previousTime) / 1000; // in seconds
                    const distanceDelta = Math.abs(lipDistance - previousLipDistance);
                    lipMovementSpeed = timeDelta > 0 ? distanceDelta / timeDelta : 0;
                }
                previousLipDistance = lipDistance;
                previousTime = now;
                
                // Update lip openness history
                lipOpennessHistory.push(lipDistance);
                if (lipOpennessHistory.length > HISTORY_LENGTH) {
                    lipOpennessHistory.shift();
                }
                
                // Determine talking state
                const wasTalking = isTalking;
                isTalking = lipDistance > lipDistanceThreshold && lipMovementSpeed > 5;
                
                // Update UI
                opennessValue.textContent = lipDistance.toFixed(1);
                speedValue.textContent = lipMovementSpeed.toFixed(1);
                statusValue.textContent = isTalking ? "Talking" : "Idle";
                statusValue.style.color = isTalking ? "#4cc9f0" : "#6c757d";
                
                // Visual feedback
                if (isTalking) {
                    ctx.fillStyle = 'rgba(0, 255, 0, 0.2)';
                    ctx.fillRect(0, 0, canvas.width, canvas.height);
                }
                
                // Draw lip landmarks
                drawLipLandmarks(landmarks, lipLandmarks);
                
                // Extract and enhance lip region
                extractLipRegion(landmarks, lipLandmarks);
            }
        }
        
        // Draw lip landmarks
        function drawLipLandmarks(landmarks, indices) {
            ctx.strokeStyle = 'yellow';
            ctx.lineWidth = 2;
            
            // Draw outer lip contour
            ctx.beginPath();
            for (let i = 0; i < 10; i++) {
                const point = landmarks[indices[i]];
                const x = point.x * canvas.width;
                const y = point.y * canvas.height;
                if (i === 0) ctx.moveTo(x, y);
                else ctx.lineTo(x, y);
            }
            ctx.closePath();
            ctx.stroke();
            
            // Draw inner lip contour
            ctx.beginPath();
            for (let i = 10; i < 20; i++) {
                const point = landmarks[indices[i]];
                const x = point.x * canvas.width;
                const y = point.y * canvas.height;
                if (i === 10) ctx.moveTo(x, y);
                else ctx.lineTo(x, y);
            }
            ctx.closePath();
            ctx.stroke();
            
            // Draw individual points
            ctx.fillStyle = 'red';
            for (let i = 0; i < indices.length; i++) {
                const point = landmarks[indices[i]];
                const x = point.x * canvas.width;
                const y = point.y * canvas.height;
                ctx.beginPath();
                ctx.arc(x, y, 2, 0, 2 * Math.PI);
                ctx.fill();
            }
        }
        
        // Extract and enhance lip region
        function extractLipRegion(landmarks, indices) {
            // Find bounding box of lips
            let minX = Infinity, minY = Infinity, maxX = -Infinity, maxY = -Infinity;
            
            for (let i = 0; i < indices.length; i++) {
                const point = landmarks[indices[i]];
                minX = Math.min(minX, point.x * canvas.width);
                minY = Math.min(minY, point.y * canvas.height);
                maxX = Math.max(maxX, point.x * canvas.width);
                maxY = Math.max(maxY, point.y * canvas.height);
            }
            
            // Add padding
            const padding = 20;
            minX = Math.max(0, minX - padding);
            minY = Math.max(0, minY - padding);
            maxX = Math.min(canvas.width, maxX + padding);
            maxY = Math.min(canvas.height, maxY + padding);
            
            // Clear and draw lip region
            lipCtx.clearRect(0, 0, lipMaskCanvas.width, lipMaskCanvas.height);
            
            // Get image data from the lip region
            const lipImageData = ctx.getImageData(minX, minY, maxX - minX, maxY - minY);
            
            // Create a temporary canvas to resize the lip region
            const tempCanvas = document.createElement('canvas');
            const tempCtx = tempCanvas.getContext('2d');
            tempCanvas.width = maxX - minX;
            tempCanvas.height = maxY - minY;
            tempCtx.putImageData(lipImageData, 0, 0);
            
            // Draw resized version to lip mask canvas
            lipCtx.drawImage(tempCanvas, 0, 0, lipMaskCanvas.width, lipMaskCanvas.height);
            
            // Apply enhancement
            enhanceLipImage();
        }
        
        // Enhance lip image for better visualization
        function enhanceLipImage() {
            const imageData = lipCtx.getImageData(0, 0, lipMaskCanvas.width, lipMaskCanvas.height);
            const data = imageData.data;
            
            // Simple contrast enhancement
            for (let i = 0; i < data.length; i += 4) {
                // Boost red channel
                data[i] = Math.min(255, data[i] * 1.4);
                // Reduce green and blue
                data[i + 1] = data[i + 1] * 0.7;
                data[i + 2] = data[i + 2] * 0.7;
                // Lighten shadows
                if (data[i] + data[i + 1] + data[i + 2] < 150) {
                    data[i] += 20;
                    data[i + 1] += 10;
                    data[i + 2] += 10;
                }
            }
            
            lipCtx.putImageData(imageData, 0, 0);
        }
        
        // Start the application
        function startApp() {
            if (!stream) {
                alert("Please allow camera access first");
                return;
            }
            
            isRunning = true;
            startBtn.disabled = true;
            stopBtn.disabled = false;
            
            // Start camera processing
            camera = new Camera(video, {
                onFrame: async () => {
                    await faceMesh.send({image: video});
                },
                width: video.videoWidth,
                height: video.videoHeight
            });
            camera.start();
            
            // Start speech recognition
            startSpeechRecognition();
            
            addSpeechBubble("System", "Application started. Begin speaking...", "system");
        }
        
        // Stop the application
        function stopApp() {
            isRunning = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;
            
            // Stop camera processing
            if (camera) {
                camera.stop();
                camera = null;
            }
            
            // Stop speech recognition
            if (speechRecognition) {
                speechRecognition.stop();
                updateSpeechStatus(false, "Speech Recognition: Stopped");
            }
            
            addSpeechBubble("System", "Application stopped", "system");
        }
        
        // Start speech recognition
        function startSpeechRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            
            if (!SpeechRecognition) {
                updateSpeechStatus(false, "Speech Recognition: Not supported");
                addSpeechBubble("System", "Speech recognition not supported in your browser", "system");
                return;
            }
            
            speechRecognition = new SpeechRecognition();
            speechRecognition.continuous = true;
            speechRecognition.interimResults = true;
            
            speechRecognition.onstart = () => {
                updateSpeechStatus(true, "Speech Recognition: Listening...");
            };
            
            speechRecognition.onerror = (event) => {
                updateSpeechStatus(false, `Speech Recognition: Error (${event.error})`);
                console.error("Speech recognition error:", event.error);
                
                // Try to restart if there was an error
                if (isRunning) {
                    setTimeout(() => {
                        if (isRunning) {
                            speechRecognition.start();
                        }
                    }, 1000);
                }
            };
            
            speechRecognition.onend = () => {
                if (isRunning) {
                    // Restart recognition if app is still running
                    setTimeout(() => {
                        if (isRunning) {
                            speechRecognition.start();
                        }
                    }, 100);
                }
            };
            
            speechRecognition.onresult = (event) => {
                let interimTranscript = '';
                let finalTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                if (finalTranscript) {
                    lastSpeech = finalTranscript;
                    addSpeechBubble("You", finalTranscript, "user");
                    
                    // Check if we're still talking based on lip movement
                    if (!isTalking) {
                        // addSpeechBubble("System", "Detected speech but no lip movement. Are you speaking?", "system");
                    }
                }
                
                // Optional: Show interim results
                // if (interimTranscript) {
                //     console.log("Interim:", interimTranscript);
                // }
            };
            
            try {
                speechRecognition.start();
            } catch (e) {
                console.error("Error starting speech recognition:", e);
                updateSpeechStatus(false, "Speech Recognition: Error starting");
            }
        }
        /*
        function quilltypebotRephrase(text) {
            // Skip very short texts
            if (text.split(' ').length < 3) {
                return text; // Not enough content to rephrase meaningfully
            }

            // Choose a rephrasing style randomly
            const style = Math.floor(Math.random() * 4);

            switch (style) {
                case 0: return synonymRephrase(text);
                case 1: return restructureSentence(text);
                case 2: return changeVoice(text);
                case 3: return combineTechniques(text);
                default: return text;
            }
        }

        // Replace words with synonyms
        function synonymRephrase(text) {
            const synonymMap = {
                "hello": ["hi", "greetings", "hey there"],
                "good": ["great", "excellent", "superb", "fine"],
                "bad": ["poor", "terrible", "awful", "subpar"],
                "happy": ["joyful", "content", "pleased", "delighted"],
                "sad": ["unhappy", "depressed", "down", "melancholy"],
                "big": ["large", "huge", "enormous", "gigantic"],
                "small": ["little", "tiny", "petite", "miniature"],
                "fast": ["quick", "rapid", "speedy", "swift"],
                "slow": ["leisurely", "sluggish", "unhurried", "gradual"],
                "important": ["significant", "crucial", "vital", "essential"],
                "think": ["believe", "consider", "ponder", "reflect"],
                "make": ["create", "produce", "construct", "fabricate"],
                "use": ["utilize", "employ", "apply", "operate"],
                "help": ["assist", "aid", "support", "guide"],
                "show": ["demonstrate", "display", "exhibit", "present"],
                "tell": ["inform", "notify", "advise", "apprise"],
                "ask": ["inquire", "question", "query", "request"],
                "need": ["require", "want", "demand", "necessitate"],
                "try": ["attempt", "endeavor", "strive", "undertake"],
                "change": ["alter", "modify", "adjust", "transform"],
                "like": ["enjoy", "prefer", "favor", "appreciate"],
                "because": ["since", "as", "due to", "owing to"],
                "if": ["whether", "provided that", "in case", "assuming"],
                "but": ["however", "nevertheless", "yet", "although"],
                "so": ["therefore", "thus", "consequently", "hence"],
                "very": ["extremely", "exceedingly", "immensely", "remarkably"]
            };

            const words = text.split(' ');
            let changed = false;

            for (let i = 0; i < words.length; i++) {
                const word = words[i].toLowerCase().replace(/[.,\/#!$%\^&\*;:{}=\-_`~()]/g, '');
                if (synonymMap[word]) {
                    // Keep original capitalization
                    const isCapitalized = words[i][0] === words[i][0].toUpperCase();
                    const synonyms = synonymMap[word];
                    const replacement = synonyms[Math.floor(Math.random() * synonyms.length)];
                    words[i] = isCapitalized
                        ? replacement.charAt(0).toUpperCase() + replacement.slice(1)
                        : replacement;
                    changed = true;
                }
            }

            return changed ? words.join(' ') : restructureSentence(text);
        }

        // Restructure the sentence without changing meaning
        function restructureSentence(text) {
            // Simple sentence restructuring patterns
            const patterns = [
                // Move prepositional phrases
                {
                    regex: /(.+?)(,?\s+[a-z]+ing\s+.+?)(\s+[a-z]+\s+)([^,.]+)/i,
                    replace: '$1$3$4$2'
                },
                // Change "X is Y" to "Y is what X is"
                {
                    regex: /([A-Z][^ ]+)\s+(is|are|was|were)\s+([^,.]+)/i,
                    replace: '$3 is what $1 $2'
                },
                // Change "I think X" to "X is what I think"
                {
                    regex: /(I\s+[a-z]+\s+)([^,.]+)/i,
                    replace: '$2 is what $1'
                },
                // Change "X can Y" to "Y is possible for X"
                {
                    regex: /([A-Z][^ ]+)\s+(can|could)\s+([^,.]+)/i,
                    replace: '$3 is possible for $1'
                },
                // Change "X should Y" to "Y is what X should do"
                {
                    regex: /([A-Z][^ ]+)\s+(should|must)\s+([^,.]+)/i,
                    replace: '$3 is what $1 $2 do'
                }
            ];

            // Try each pattern until one matches
            for (const pattern of patterns) {
                if (pattern.regex.test(text)) {
                    return text.replace(pattern.regex, pattern.replace);
                }
            }

            // If no patterns matched, try adding a modifier
            const modifiers = [
                "Essentially, ",
                "In other words, ",
                "To put it differently, ",
                "That is to say, ",
                "Put simply, ",
                "In simple terms, "
            ];

            return modifiers[Math.floor(Math.random() * modifiers.length)] + text;
        }

        // Change between active and passive voice
        function changeVoice(text) {
            // Simple active to passive transformations
            const activeToPassive = [
                {
                    regex: /([A-Z][^ ]+)\s+([a-z]+ed)\s+([^,.]+)/i,
                    replace: '$3 was $2 by $1'
                },
                {
                    regex: /([A-Z][^ ]+)\s+([a-z]+s)\s+([^,.]+)/i,
                    replace: '$3 is $2 by $1'
                },
                {
                    regex: /([A-Z][^ ]+)\s+([a-z]+ing)\s+([^,.]+)/i,
                    replace: '$3 is being $2 by $1'
                }
            ];

            // Simple passive to active transformations
            const passiveToActive = [
                {
                    regex: /([^ ]+)\s+was\s+([a-z]+ed)\s+by\s+([^,.]+)/i,
                    replace: '$3 $2 $1'
                },
                {
                    regex: /([^ ]+)\s+is\s+([a-z]+ed)\s+by\s+([^,.]+)/i,
                    replace: '$3 $2s $1'
                },
                {
                    regex: /([^ ]+)\s+is\s+being\s+([a-z]+ed)\s+by\s+([^,.]+)/i,
                    replace: '$3 is $2ing $1'
                }
            ];

            // Check if sentence is passive
            const isPassive = /(was|is|are|were)\s+[a-z]+ed\s+by/i.test(text);

            if (isPassive) {
                for (const pattern of passiveToActive) {
                    if (pattern.regex.test(text)) {
                        return text.replace(pattern.regex, pattern.replace);
                    }
                }
            } else {
                for (const pattern of activeToPassive) {
                    if (pattern.regex.test(text)) {
                        return text.replace(pattern.regex, pattern.replace);
                    }
                }
            }

            return restructureSentence(text);
        }
        **/
        // Add a speech bubble to the output
        function addSpeechBubble(speaker, text, type) {
            const bubble = document.createElement('div');
            bubble.className = `speech-bubble ${type}`;
            bubble.innerHTML = `<strong>${speaker}:</strong> ${text}`;
            speechOutput.appendChild(bubble);
            speechOutput.scrollTop = speechOutput.scrollHeight;
        }
        
        // Clear the speech output
        function clearOutput() {
            speechOutput.innerHTML = '';
        }
        
        // Rephrase the last spoken sentence
        function rephraseLast() {
            if (!lastSpeech) {
                addSpeechBubble("System", "No speech to rephrase", "system");
                return;
            }
            
            // In a real app, you would call an API here
            const rephrased = simulateRephrase(lastSpeech);
            addSpeechBubble("System", `Rephrased: ${rephrased}`, "system");
        }
        
        // Simulate rephrasing (in a real app, call an API)
        function simulateRephrase(text) {
            const rephrases = [
                `Let me rephrase that: ${text}`,
                `In other words: ${text.split(' ').reverse().join(' ')}`,
                `Alternative phrasing: ${text.toLowerCase()}`,
                `Another way to say this: "${text.replace(/./g, '')} ${text}"`,
                `Paraphrased version: ${text.slice(0, text.length/2)}...${text.slice(text.length/2)}`
            ];
            return rephrases[Math.floor(Math.random() * rephrases.length)];
        }
        
        // Update the lip distance threshold
        function updateThreshold() {
            lipDistanceThreshold = parseInt(thresholdSlider.value);
            thresholdValue.textContent = lipDistanceThreshold;
        }
        
        // Update camera status indicator
        function updateCameraStatus(active, text = null) {
            cameraStatus.className = `status-dot ${active ? 'active' : ''}`;
            cameraStatusText.textContent = text || (active ? "Camera: Active" : "Camera: Inactive");
        }
        
        // Update speech recognition status indicator
        function updateSpeechStatus(active, text = null) {
            speechStatus.className = `status-dot ${active ? 'active' : ''}`;
            speechStatusText.textContent = text || (active ? "Speech Recognition: Active" : "Speech Recognition: Inactive");
        }
        
        // Initialize the app when the page loads
        window.addEventListener('DOMContentLoaded', init);
    </script>
</body>
</html>
